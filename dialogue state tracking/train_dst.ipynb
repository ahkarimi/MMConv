{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.cudnn.benchmark = True\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloader import TextDataset\n",
    "from model_dst import DST\n",
    "from utils.model_utils import loop, get_device_ids, CustomPaddingTensorCollator\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "transformer_model = 'bert-base-uncased'\n",
    "input_format = 'dst'\n",
    "model_name = f'{input_format}_{transformer_model}'\n",
    "cuda = True\n",
    "mixed_precision = False\n",
    "clear_cache_every = 200\n",
    "\n",
    "device_ids = get_device_ids(cuda=cuda)\n",
    "print('Using devices: {}'.format(device_ids))\n",
    "\n",
    "BATCH_SIZE = 64#int(sys.argv[1])\n",
    "print('Batch size: {}'.format(BATCH_SIZE))\n",
    "MINI_BATCH_SIZE = min((len(device_ids) << 5) if cuda else 32, BATCH_SIZE)\n",
    "print('Mini batch size for training: {}'.format(MINI_BATCH_SIZE))\n",
    "BATCH_SIZE_EVAL = min((len(device_ids) << 6) if cuda else 64, BATCH_SIZE << 1)\n",
    "print('Batch size for evaluation: {}'.format(BATCH_SIZE_EVAL))\n",
    "\n",
    "assert BATCH_SIZE % MINI_BATCH_SIZE == 0\n",
    "batch_iters = BATCH_SIZE // MINI_BATCH_SIZE\n",
    "\n",
    "workers = max(min(16, MINI_BATCH_SIZE >> 3), 4)\n",
    "workers_eval = max(min(8, BATCH_SIZE_EVAL >> 3), 4)\n",
    "\n",
    "\n",
    "train = TextDataset.create_data(f'resources/train.{input_format}', tokenizer_or_transformer_model=transformer_model, split=(1,), shuffle=True, task='dst', data_var_token='<|belief|>', split_data_var='; ')\n",
    "val = TextDataset.create_data(f'resources/val.{input_format}', tokenizer_or_transformer_model=transformer_model, split=(1,), training=False, shuffle=False, task='dst', data_var_token='<|belief|>', split_data_var='; ', reduce_slots_without_values=False)\n",
    "test = TextDataset.create_data(f'resources/test.{input_format}', tokenizer_or_transformer_model=transformer_model, split=(1,), training=False, shuffle=False, task='dst', data_var_token='<|belief|>', split_data_var='; ', reduce_slots_without_values=False)\n",
    "\n",
    "pad_value = train.tokenizer.pad_token_id\n",
    "if pad_value is None:\n",
    "    pad_value = train.tokenizer.eos_token_id\n",
    "\n",
    "key2pad_id = {\n",
    "    'input_ids': pad_value,\n",
    "    'span': -1\n",
    "}\n",
    "\n",
    "collator= CustomPaddingTensorCollator(key2pad_id=key2pad_id)\n",
    "\n",
    "dataloader_train = DataLoader(train, batch_size=MINI_BATCH_SIZE, shuffle=True, num_workers=workers, pin_memory=True, drop_last=False, collate_fn=collator)\n",
    "dataloader_val = DataLoader(val, batch_size=BATCH_SIZE_EVAL, shuffle=False, num_workers=workers_eval, pin_memory=True, drop_last=False, collate_fn=collator)\n",
    "dataloader_test = DataLoader(test, batch_size=BATCH_SIZE_EVAL, shuffle=False, num_workers=workers_eval, pin_memory=True, drop_last=False, collate_fn=collator)\n",
    "\n",
    "lr=3e-5\n",
    "warmup_epochs = 0.5\n",
    "epochs = 5\n",
    "epochs_per_val = 1\n",
    "epochs_per_test = 1\n",
    "min_epoch_for_val = 0\n",
    "min_epoch_for_test = 0\n",
    "steps = epochs * len(dataloader_train)\n",
    "\n",
    "model = DST(transformer_model, warmup_ratio=warmup_epochs / epochs, num_training_steps=steps, lr=lr, device_idxs=device_ids, mixed_precision=mixed_precision, cuda=cuda, pad_value=pad_value)\n",
    "# model.load_model('checkpoint/dstc_bert-base-uncased_XXX.th')\n",
    "if cuda:\n",
    "    # if len(device_ids) > 1:\n",
    "    #     model = DataParallel(model, device_ids=device_ids, output_device=device_ids[-1])\n",
    "    model.to('cuda:' + str(device_ids[0]))\n",
    "\n",
    "pbar = tqdm(range(epochs))\n",
    "model_name += '_latest_rebalanced_low_lr'\n",
    "for i in pbar:\n",
    "    pbar.set_description(f'Epoch {i + 1}/{epochs}')\n",
    "    loop(model, dataloader_train, batch_iters=batch_iters, clear_cache_every=clear_cache_every, train=True, cuda=cuda, model_name=model_name)\n",
    "    if (i + 1) >= min_epoch_for_val and (i + 1) % epochs_per_val == 0:\n",
    "        loop(model, dataloader_val, batch_iters=1, clear_cache_every=clear_cache_every, train=False, cuda=cuda, model_name=model_name)\n",
    "    if (i + 1) >= min_epoch_for_test and (i + 1) % epochs_per_test == 0:\n",
    "        loop(model, dataloader_test, batch_iters=1, clear_cache_every=clear_cache_every, train=False, cuda=cuda, model_name=model_name, save_best=False, save_results=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
